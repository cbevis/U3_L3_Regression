{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Comparison Exercise\n",
    "Compare three versions of logistic regression\n",
    "\n",
    "Selected dataset from UC Irvine dataset repository:\n",
    "https://archive.ics.uci.edu/ml/datasets/Epileptic+Seizure+Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.cluster import KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('epileptic_seizures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   X1   X2   X3   X4   X5   X6   X7   X8   X9 ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33 ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244 ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85 ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87 ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21 ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>X22.V1.114</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-23</td>\n",
       "      <td>-26</td>\n",
       "      <td>-36</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-18</td>\n",
       "      <td>-37</td>\n",
       "      <td>-47</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>X19.V1.354</td>\n",
       "      <td>-47</td>\n",
       "      <td>-11</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>141</td>\n",
       "      <td>211</td>\n",
       "      <td>246</td>\n",
       "      <td>240</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>-65</td>\n",
       "      <td>-33</td>\n",
       "      <td>-7</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>117</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>X8.V1.28</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>-13</td>\n",
       "      <td>-16</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-65</td>\n",
       "      <td>-48</td>\n",
       "      <td>-61</td>\n",
       "      <td>-62</td>\n",
       "      <td>-67</td>\n",
       "      <td>-30</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11498</th>\n",
       "      <td>X10.V1.932</td>\n",
       "      <td>-40</td>\n",
       "      <td>-25</td>\n",
       "      <td>-9</td>\n",
       "      <td>-12</td>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>135</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>X16.V1.210</td>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>-59</td>\n",
       "      <td>-25</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  X1  X2  X3  X4   X5   X6   X7   X8   X9 ...  X170  X171  \\\n",
       "11495  X22.V1.114 -22 -22 -23 -26  -36  -42  -45  -42  -45 ...    15    16   \n",
       "11496  X19.V1.354 -47 -11  28  77  141  211  246  240  193 ...   -65   -33   \n",
       "11497    X8.V1.28  14   6 -13 -16   10   26   27   -9    4 ...   -65   -48   \n",
       "11498  X10.V1.932 -40 -25  -9 -12   -2   12    7   19   22 ...   121   135   \n",
       "11499  X16.V1.210  29  41  57  72   74   62   54   43   31 ...   -59   -25   \n",
       "\n",
       "       X172  X173  X174  X175  X176  X177  X178  y  \n",
       "11495    12     5    -1   -18   -37   -47   -48  2  \n",
       "11496    -7    14    27    48    77   117   170  1  \n",
       "11497   -61   -62   -67   -30    -2    -1    -8  5  \n",
       "11498   148   143   116    86    68    59    55  3  \n",
       "11499    -4     2     5     4    -2     2    20  4  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11500 entries, 0 to 11499\n",
      "Columns: 180 entries, Unnamed: 0 to y\n",
      "dtypes: int64(179), object(1)\n",
      "memory usage: 15.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.00000</td>\n",
       "      <td>11500.00000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-11.581391</td>\n",
       "      <td>-10.911565</td>\n",
       "      <td>-10.187130</td>\n",
       "      <td>-9.143043</td>\n",
       "      <td>-8.009739</td>\n",
       "      <td>-7.003478</td>\n",
       "      <td>-6.502087</td>\n",
       "      <td>-6.68713</td>\n",
       "      <td>-6.55800</td>\n",
       "      <td>-6.168435</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.145739</td>\n",
       "      <td>-11.630348</td>\n",
       "      <td>-12.943478</td>\n",
       "      <td>-13.668870</td>\n",
       "      <td>-13.363304</td>\n",
       "      <td>-13.045043</td>\n",
       "      <td>-12.705130</td>\n",
       "      <td>-12.426000</td>\n",
       "      <td>-12.195652</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>165.626284</td>\n",
       "      <td>166.059609</td>\n",
       "      <td>163.524317</td>\n",
       "      <td>161.269041</td>\n",
       "      <td>160.998007</td>\n",
       "      <td>161.328725</td>\n",
       "      <td>161.467837</td>\n",
       "      <td>162.11912</td>\n",
       "      <td>162.03336</td>\n",
       "      <td>160.436352</td>\n",
       "      <td>...</td>\n",
       "      <td>164.652883</td>\n",
       "      <td>166.149790</td>\n",
       "      <td>168.554058</td>\n",
       "      <td>168.556486</td>\n",
       "      <td>167.257290</td>\n",
       "      <td>164.241019</td>\n",
       "      <td>162.895832</td>\n",
       "      <td>162.886311</td>\n",
       "      <td>164.852015</td>\n",
       "      <td>1.414275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1839.000000</td>\n",
       "      <td>-1838.000000</td>\n",
       "      <td>-1835.000000</td>\n",
       "      <td>-1845.000000</td>\n",
       "      <td>-1791.000000</td>\n",
       "      <td>-1757.000000</td>\n",
       "      <td>-1832.000000</td>\n",
       "      <td>-1778.00000</td>\n",
       "      <td>-1840.00000</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>-1865.000000</td>\n",
       "      <td>-1642.000000</td>\n",
       "      <td>-1723.000000</td>\n",
       "      <td>-1866.000000</td>\n",
       "      <td>-1863.000000</td>\n",
       "      <td>-1781.000000</td>\n",
       "      <td>-1727.000000</td>\n",
       "      <td>-1829.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-55.00000</td>\n",
       "      <td>-55.00000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.00000</td>\n",
       "      <td>-7.00000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1726.000000</td>\n",
       "      <td>1713.000000</td>\n",
       "      <td>1697.000000</td>\n",
       "      <td>1612.000000</td>\n",
       "      <td>1518.000000</td>\n",
       "      <td>1816.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.00000</td>\n",
       "      <td>2047.00000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1777.000000</td>\n",
       "      <td>1472.000000</td>\n",
       "      <td>1319.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1733.000000</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X1            X2            X3            X4            X5  \\\n",
       "count  11500.000000  11500.000000  11500.000000  11500.000000  11500.000000   \n",
       "mean     -11.581391    -10.911565    -10.187130     -9.143043     -8.009739   \n",
       "std      165.626284    166.059609    163.524317    161.269041    160.998007   \n",
       "min    -1839.000000  -1838.000000  -1835.000000  -1845.000000  -1791.000000   \n",
       "25%      -54.000000    -55.000000    -54.000000    -54.000000    -54.000000   \n",
       "50%       -8.000000     -8.000000     -7.000000     -8.000000     -8.000000   \n",
       "75%       34.000000     35.000000     36.000000     36.000000     35.000000   \n",
       "max     1726.000000   1713.000000   1697.000000   1612.000000   1518.000000   \n",
       "\n",
       "                 X6            X7           X8           X9           X10  \\\n",
       "count  11500.000000  11500.000000  11500.00000  11500.00000  11500.000000   \n",
       "mean      -7.003478     -6.502087     -6.68713     -6.55800     -6.168435   \n",
       "std      161.328725    161.467837    162.11912    162.03336    160.436352   \n",
       "min    -1757.000000  -1832.000000  -1778.00000  -1840.00000  -1867.000000   \n",
       "25%      -54.000000    -54.000000    -55.00000    -55.00000    -54.000000   \n",
       "50%       -8.000000     -8.000000     -8.00000     -7.00000     -7.000000   \n",
       "75%       36.000000     35.000000     36.00000     36.00000     35.250000   \n",
       "max     1816.000000   2047.000000   2047.00000   2047.00000   2047.000000   \n",
       "\n",
       "           ...               X170          X171          X172          X173  \\\n",
       "count      ...       11500.000000  11500.000000  11500.000000  11500.000000   \n",
       "mean       ...         -10.145739    -11.630348    -12.943478    -13.668870   \n",
       "std        ...         164.652883    166.149790    168.554058    168.556486   \n",
       "min        ...       -1867.000000  -1865.000000  -1642.000000  -1723.000000   \n",
       "25%        ...         -55.000000    -56.000000    -56.000000    -56.000000   \n",
       "50%        ...          -9.000000    -10.000000    -10.000000    -10.000000   \n",
       "75%        ...          34.000000     34.000000     33.000000     33.000000   \n",
       "max        ...        1777.000000   1472.000000   1319.000000   1436.000000   \n",
       "\n",
       "               X174          X175          X176          X177          X178  \\\n",
       "count  11500.000000  11500.000000  11500.000000  11500.000000  11500.000000   \n",
       "mean     -13.363304    -13.045043    -12.705130    -12.426000    -12.195652   \n",
       "std      167.257290    164.241019    162.895832    162.886311    164.852015   \n",
       "min    -1866.000000  -1863.000000  -1781.000000  -1727.000000  -1829.000000   \n",
       "25%      -55.000000    -56.000000    -55.000000    -55.000000    -55.000000   \n",
       "50%      -10.000000     -9.000000     -9.000000     -9.000000     -9.000000   \n",
       "75%       34.000000     34.000000     34.000000     34.000000     34.000000   \n",
       "max     1733.000000   1958.000000   2047.000000   2047.000000   1915.000000   \n",
       "\n",
       "                  y  \n",
       "count  11500.000000  \n",
       "mean       3.000000  \n",
       "std        1.414275  \n",
       "min        1.000000  \n",
       "25%        2.000000  \n",
       "50%        3.000000  \n",
       "75%        4.000000  \n",
       "max        5.000000  \n",
       "\n",
       "[8 rows x 179 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    object\n",
       "X1             int64\n",
       "X2             int64\n",
       "X3             int64\n",
       "X4             int64\n",
       "X5             int64\n",
       "X6             int64\n",
       "X7             int64\n",
       "X8             int64\n",
       "X9             int64\n",
       "X10            int64\n",
       "X11            int64\n",
       "X12            int64\n",
       "X13            int64\n",
       "X14            int64\n",
       "X15            int64\n",
       "X16            int64\n",
       "X17            int64\n",
       "X18            int64\n",
       "X19            int64\n",
       "X20            int64\n",
       "X21            int64\n",
       "X22            int64\n",
       "X23            int64\n",
       "X24            int64\n",
       "X25            int64\n",
       "X26            int64\n",
       "X27            int64\n",
       "X28            int64\n",
       "X29            int64\n",
       "               ...  \n",
       "X150           int64\n",
       "X151           int64\n",
       "X152           int64\n",
       "X153           int64\n",
       "X154           int64\n",
       "X155           int64\n",
       "X156           int64\n",
       "X157           int64\n",
       "X158           int64\n",
       "X159           int64\n",
       "X160           int64\n",
       "X161           int64\n",
       "X162           int64\n",
       "X163           int64\n",
       "X164           int64\n",
       "X165           int64\n",
       "X166           int64\n",
       "X167           int64\n",
       "X168           int64\n",
       "X169           int64\n",
       "X170           int64\n",
       "X171           int64\n",
       "X172           int64\n",
       "X173           int64\n",
       "X174           int64\n",
       "X175           int64\n",
       "X176           int64\n",
       "X177           int64\n",
       "X178           int64\n",
       "y              int64\n",
       "Length: 180, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Unnamed: 0', 'y']).values\n",
    "y = np.where(df['y'] == 1, 1, 0).ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of epilepsy occurances is 20.0%\n"
     ]
    }
   ],
   "source": [
    "print('The percentage of epilepsy occurances is {}%'.format(y.sum()/len(y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8188405797101449"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', max_iter=200, C=10**9)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2746    7]\n",
      " [ 618   79]]\n",
      "The score of the regular logistic regression is 0.819\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('The score of the regular logistic regression is {:.3f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "ridge = LogisticRegression(solver='liblinear', penalty='l2', max_iter=200)\n",
    "grid_ridge = GridSearchCV(ridge, param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=200, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303105590062112"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228985507246377"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2733   20]\n",
      " [ 591  106]]\n",
      "The ridge score on the test set is 0.823\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_ridge.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('The ridge score on the test set is {:.3f}'.format(grid_ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=200, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LogisticRegression(solver='liblinear', penalty='l1', max_iter=200)\n",
    "grid_lass = GridSearchCV(lasso, param_grid, cv=3)\n",
    "grid_lass.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lass.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826583850931677"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lass.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8182608695652174"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lass.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2746    7]\n",
      " [ 620   77]]\n",
      "The lasso score on the test set is 0.818\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_lass.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('The lasso score on the test set is {:.3f}'.format(grid_lass.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with PCA for feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "transform = pca.transform(X_train)\n",
    "\n",
    "features = range(50)\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(features, pca.explained_variance_[0:50])\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.title('PCA features and variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of PCA on training set with 100 components is 0.83\n",
      "Score of PCA on test training set with 100 components is 0.82\n",
      "The confusion matrix is:\n",
      " [[2751    2]\n",
      " [ 635   62]]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "pca_n = PCA(n_components=n)\n",
    "pipeline = make_pipeline(pca_n, logreg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print('Score of PCA on training set with {} components is {:.2f}'.format(n, pipeline.score(X_train, y_train)))\n",
    "print('Score of PCA on test training set with {} components is {:.2f}'.format(n, score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try standard scaling parameters before PCA - model gets worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of scaled PCA with 150 components is 0.524927536231884\n",
      "The confusion matrix is:\n",
      " [[1474 1279]\n",
      " [ 360  337]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "pipeline_scaled = make_pipeline(scaler, pca_n, logreg)\n",
    "pipeline_scaled.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print('Score of scaled PCA with {} components is {}'.format(n, score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of K_best with 30 components is 0.81\n",
      "The confusion matrix is:\n",
      " [[2753    0]\n",
      " [ 663   34]]\n"
     ]
    }
   ],
   "source": [
    "num_features = 30\n",
    "\n",
    "selectK = SelectKBest(f_classif, k=num_features)\n",
    "\n",
    "pipeline_K = make_pipeline(selectK, logreg)\n",
    "pipeline_K.fit(X_train, y_train)\n",
    "y_pred = pipeline_K.predict(X_test)\n",
    "score = pipeline_K.score(X_test, y_test)\n",
    "\n",
    "print('Score of K_best with {} components is {:.2f}'.format(num_features, score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try another approach - Trees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97020484, 0.96151459, 0.96459627, 0.96146675, 0.96581728])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a basic tree model\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=10)\n",
    "cross_val_score(rfc, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Random Forest Classifier is 0.97\n",
      "The confusion matrix is:\n",
      " [[2707   46]\n",
      " [  69  628]]\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "score = rfc.score(X_test, y_test)\n",
    "\n",
    "print('Score of Random Forest Classifier is {:.2f}'.format(score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of rfc with PCA on training set with 20 components is 1.00\n",
      "Score of rfc with PCA on test training set with 20 components is 0.96\n",
      "The confusion matrix is:\n",
      " [[2684   69]\n",
      " [  59  638]]\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "\n",
    "pca_n = PCA(n_components=n)\n",
    "pipeline = make_pipeline(pca_n, rfc)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print('Score of rfc with PCA on training set with {} components is {:.2f}'.format(n, pipeline.score(X_train, y_train)))\n",
    "print('Score of rfc with PCA on test training set with {} components is {:.2f}'.format(n, score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of K_best with 30 components is 0.96\n",
      "The confusion matrix is:\n",
      " [[2701   52]\n",
      " [  91  606]]\n"
     ]
    }
   ],
   "source": [
    "num_features = 30\n",
    "\n",
    "selectK = SelectKBest(f_classif, k=num_features)\n",
    "\n",
    "pipeline_K = make_pipeline(selectK, rfc)\n",
    "pipeline_K.fit(X_train, y_train)\n",
    "y_pred = pipeline_K.predict(X_test)\n",
    "score = pipeline_K.score(X_test, y_test)\n",
    "\n",
    "print('Score of K_best with {} components is {:.2f}'.format(num_features, score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons Learned\n",
    "\n",
    "This dataset is modeled much better by an ensemble Random Forest Classifier than by the logistic regressions.  That being said, out of the three logistic models, the Ridge Classifier performed the best. The regular logistic regression also improves if we try PCA on it and limit the components. Standard scaling the features before PCA made the model much worse.  \n",
    "\n",
    "\n",
    "The best model is the Ridge Logistic Regression with PCA performed on the parameters and then using PCA for feature reduction. Since the features are already annonymized, not much interpretation is lost by using PCA features instead of regular features.  I used the same C value of .001 as found through the grid search.  Smaller values of C indicate greater regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The winning logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of PCA on training set with 110 components is 0.84\n",
      "Score of PCA on test training set with 110 components is 0.83\n",
      "The confusion matrix is:\n",
      " [[2747    6]\n",
      " [ 588  109]]\n"
     ]
    }
   ],
   "source": [
    "n = 110\n",
    "ridge2 = LogisticRegression(solver='liblinear', penalty='l2', max_iter=200, C=.001)\n",
    "\n",
    "pca_n = PCA(n_components=n)\n",
    "pipeline = make_pipeline(pca_n, ridge2)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print('Score of PCA on training set with {} components is {:.2f}'.format(n, pipeline.score(X_train, y_train)))\n",
    "print('Score of PCA on test training set with {} components is {:.2f}'.format(n, score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just checking that select K best for similar feature numbers isn't as good, nope, slightly worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of K_best with 110 components is 0.82\n",
      "The confusion matrix is:\n",
      " [[2741   12]\n",
      " [ 607   90]]\n"
     ]
    }
   ],
   "source": [
    "num_features = 110\n",
    "\n",
    "selectK = SelectKBest(f_classif, k=num_features)\n",
    "\n",
    "pipeline_K = make_pipeline(selectK, ridge2)\n",
    "pipeline_K.fit(X_train, y_train)\n",
    "y_pred = pipeline_K.predict(X_test)\n",
    "score = pipeline_K.score(X_test, y_test)\n",
    "\n",
    "print('Score of K_best with {} components is {:.2f}'.format(num_features, score))\n",
    "print('The confusion matrix is:\\n {}'.format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
